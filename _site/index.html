<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Ted Östrem &middot; A Jekyll theme
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body> 
    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Ted Östrem
        </a>
      </h1>
      <p class="lead">A Swedish software engineer and contractor in Beijing. Enjoy helping startups with backend systems, infrastructure, devops, automation, tool building and development processes.
</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="https://github.com/tedostrem">GitHub</a>
      <a class="sidebar-nav-item" href="https://linkedin.com/in/tedostrem1">Linkedin</a>
      <a class="sidebar-nav-item" href="mailto: ted.ostrem@gmail.com">ted.ostrem@gmail.com</a>
    </nav>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/devops/2016/07/21/monorepo-shared-code-and-isolated-fast-docker-builds/">
        Monorepo, Shared Code and Isolated Fast Docker Builds
      </a>
    </h1>

    <span class="post-date">21 Jul 2016</span>

    <p>Docker does not make it easy for those who want to do isolated builds of separate applications using shared code in a monorepo.</p>

<p>There are probably many ways to solve it, but for me, finding a way that works in a consistent way for all of the projects and languages in our code base was not trivial.
Here I’m going to present a solution that works for us at Traintracks.</p>

<p>This solution is agnostic to language, package manager, build system, project hierarchy and can be implemented in the same way throughout your whole stack. (Please do comment if you notice a case where it’s not)</p>

<p>So here it goes!</p>

<h5 id="cached-dependencies">Cached dependencies</h5>
<p>If you’ve ever used Scala and SBT, you probably know that you’ll have enough time to grow and cut your toenails (might even start eating them) in between builds if your build cache gets reset at each build.</p>

<p>The immutable nature of docker plus the fact that SBT does not have have a <code class="highlighter-rouge">package.json</code> or a <code class="highlighter-rouge">requirements.txt</code> file like <code class="highlighter-rouge">npm</code>/<code class="highlighter-rouge">pip</code> means that we can’t cache our dependencies easily.</p>

<p>Every time we update some code we are back to 0 because the downloading of dependencies and building of code happens in the same step.</p>

<p><strong>Build containers to the rescue?</strong></p>

<p>It goes pretty much like this.</p>

<ol>
  <li>You create a container with all the tools to build your application.</li>
  <li>You run the container and tell it to build your application with your project folder mounted into a folder in the container.</li>
  <li>You execute your build inside of the container and everything is persisted on your host for your next build.</li>
</ol>

<p>All good? not really, unless you also mounted your ~/.m2 or ~/.ivy2 folder or redirected them to somewhere else and also don’t mind keeping the same build artifacts shared between your host and docker container.</p>

<p>Adding to that, if you are in Vagrant and share your workspace volume with your host and have not set up NFS then be prepared for really slow build times.</p>

<p>Besides, you still want to have your <a href="http://blog.traintracks.io/building-a-devbox-with-packer-vagrant-and-ansible-2/">static dependencies cached away and separate from your dynamic dependencies</a> so that your team’s code can be built by all engineers regardless of how broken the internet is at that point. This is particularly relevant if you are behind a corporate firewall or in someplace with internet connectivity issues.</p>

<p>That means that your build container needs to already come shipped with the third party dependencies required before we execute the build in it.</p>

<p>To summarize, we need to do an initial build of the application inside the container before it can act as a pre-cached build container. As dependencies update the build container will be rebuilt.</p>

<p>Let’s continue to the next requirement.</p>

<h5 id="shared-code">Shared code</h5>
<p>Maybe you made a nice library with some transformations that you want to use both in your data ingestion app and in your query application.
On top of that, maybe one of the engineers on your team enjoys sitting in IntelliJ with all the Scala projects open in the same workspace, modifying the shared library code and recompile both of his projects from within the IDE.</p>

<p>How do we build individual applications isolated when they have shared dependencies above themselves in the project hierarchy?</p>

<p>Lets imagine a monorepo and try to figure out how to build coolapp and awesomeapp that both share the dependencies lib1 and lib2.
We are going to use Golang for this example instead of Scala (for simplicity) but the same concepts apply.</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code>├── coolapp
│   ├── coolapp.builder.dockerfile
│   ├── ...
├── awesomeapp
│   ├── awesomeapp.builder.dockerfile
│   ├── 
├── lib1
│   └── ...
└── lib2
    └── ...
└── i_am_too_fat_for_your_build_context
    └── ...
</code></pre>
</div>

<p>We can’t just execute <code class="highlighter-rouge">docker build -t coolapp .</code> inside of coolapp because lib1 and lib2 are outside of it’s context.</p>

<p>However, we can move the context up one directory and specify the dockerfile like this.</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>docker build -t coolapp -f coolapp/Dockerfile . 
</code></pre>
</div>

<p>We are getting there. but wait, there is a folder that says its too fat for your docker context and we are not even depending on it.</p>

<p>What if we have so many projects in this repo that the size of the build context we send to docker ends up being a huge build time bottleneck?</p>

<p>Typically we would add a .dockerignore file that tells docker which files to ignore when uploading the context but that won’t work here since what we want to ignore is conditional (depending on which app we are building).</p>

<p>So what we need to do is to cherry pick our build context and send it to docker (Note that we’re using GNU Tar and not BSD Tar).</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>tar -zcf - ../lib1 ../lib2 | docker build -t coolapp-builder -f coolapp/coolapp.builder.dockerfile
</code></pre>
</div>
<p><em>GNU Tar also takes –exclude-from-file where you can pass a .gitignore or a .dockerignore. Note that .gitignore have
expansion rules not supported by Tar so you are either gonna have to tar dependencies individually and concatenated, ask git for the relevant files or align to a unified ignore pattern across your libraries.</em></p>

<p>Lets have a look at the Dockerfile in coolapp.</p>
<pre><code class="language-docker">FROM golang:1.6
RUN apt-get update &amp;&amp; apt-get install -y rsync
ADD . /go/src/traintracks/
WORKDIR /go/src/traintracks/coolapp
RUN go get ./...
</code></pre>

<p>Lets build the container, jump into it and look at the content of our GOPATH.</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>docker <span class="nb">exec</span> -it coolapp-builder bash
<span class="gp">$ </span>tree <span class="nv">$GOPATH</span>
|-- bin
|   |-- coolapp
|-- pkg
|   |-- linux_amd64
|       |-- github.com
|       |  |-- Sirupsen
|       |       |-- logrus.a
|       |- traintracks
|           |-- lib1.a
|           |-- lib2.a
|-- src
    |-- github.com
    |   |- Sirupsen
    |       -- logrus
    |           |--  ...
        -- traintracks
        |-- coolapp
        |   |-- coolapp.builder.dockerfile
        |   |-- coolapp.dockerfile
        |   |-- coolapp.go
        |-- lib1
        |   -- lib1.go
        --- lib2
            -- lib2.go
</code></pre>
</div>

<p>It has downloaded our dependencies from the internet and also built coolapp-builder with our cherry picked dependencies.</p>

<p>Now we have edited a line of code in lib1 and want to rebuild coolapp.
We are going to execute the container with the build context mounted to /mount and tell it to make an rsync between /mount and the corresponding folder in the GOPATH.</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>rsync -auiv --filter<span class="o">=</span><span class="se">\"</span>:- .gitignore<span class="se">\"</span> /mount/ /go/src/traintracks/
</code></pre>
</div>
<p><em>Remember what I said about .gitignore passed into Tar, the same applies here</em></p>

<p>Now we just have to build the app again with a <code class="highlighter-rouge">go get ./...</code> and unless you have new internet dependencies since last build the build will be as fast as your CPU and disk.</p>

<p>Final step is to copy our artifacts to somewhere in the mounted folder.</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>cp -v /go/bin/coolapp  /mount/coolapp/output/
</code></pre>
</div>

<p>Back on our host we can inspect the folder again</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code>├── coolapp.builder.dockerfile
├── coolapp.go
└── output
    └── coolapp
</code></pre>
</div>

<p>So there is your coolapp binary ready for you to throw it into a plain linux container without any builds tools or source code.
This will keep your containers lean and will avoid potential leakage of code.</p>

<p>coolapp.dockerfile might look something like this</p>
<pre><code class="language-docker">FROM ubuntu:14.04
ADD output/* /usr/local/bin
CMD coolapp
</code></pre>

<h5 id="good-ol-makefiles">Good ol’ Makefiles</h5>
<p>That was a lot of steps and it might seem like a very troublesome process but actually we can wrap all of it in this <a href="https://github.com/traintracks/docker_monorepo_example/blob/master/src/traintracks/coolapp/Makefile">Makefile</a> and work ourselves towards a generalised solution that will work for all  of our projects.</p>

<p>I have created an example repository that you can clone and try out.</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>git clone git@github.com:traintracks/docker_monorepo_example.git
<span class="gp">$ </span>make builder   <span class="c"># Creates the builder container</span>
<span class="gp">$ </span>make build     <span class="c"># Builds project using builder container</span>
<span class="gp">$ </span>make runner    <span class="c"># Creates the runner container</span>
<span class="gp">$ </span>make run       <span class="c"># Runs coolapp</span>
<span class="gp">$ </span>make all       <span class="c"># Runs all of the previous steps</span>
<span class="gp">$ </span>make           <span class="c"># Runs all targets except builder</span>
</code></pre>
</div>

<p>To summarise what all of this gave us.</p>

<ul>
  <li>Pre-cached dependencies without a requirements file.</li>
  <li>Separation between build/run containers.</li>
  <li>No dirty artifacts on host.</li>
  <li>Support for a project hierarchy of your choice.</li>
  <li>Fast builds on shared disks in Vagrant.</li>
  <li>A unified build system for all your applications.</li>
</ul>

<p>If you think you might have a better solution than what I presented here or have some cool improvements please leave me a comment ! I’m more than happy to learn how others have tackled these problems.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/devops/2016/07/12/building_a_devbox_with_packer_vagrant_and_ansible/">
        Building a Devbox with Packer, Vagrant and Ansible
      </a>
    </h1>

    <span class="post-date">12 Jul 2016</span>

    <p>In the previous article <a href="/devops/2016/07/05/safeguarding_your_deployments_with_packer">Safeguarding your deployments with packer</a> we explained in theory how we can use Packer to achieve immutable server configurations.</p>

<p>At Traintracks, we not only use Packer for server deployments but also for our development environment.</p>

<p>There are many benefits to this such as:</p>

<ul>
  <li>Every engineer’s development environment is the same.</li>
  <li>New engineers can start being productive from day one.</li>
  <li>What works on my machine will work on any other engineers machine.</li>
  <li>What works on my machine will (probably) work in production.</li>
  <li>Development environment is host operating system agnostic (Even works for windows users).</li>
</ul>

<p>When using Packer for server deployments you want to keep all of your server configurations as immutable as possible. However, for a development environment, it’s just not practical to throw away your devbox and build a new one every time something in the dev environment has been updated.</p>

<p>Instead of only optimising for immutability and consistency we also need to optimise for efficiency (developer hours cost more than computer hours).</p>

<p>This is why we are gonna bring in two new concepts here:</p>

<ul>
  <li>Static dependencies (Dependencies that do not get updated very often, eg. operating system, system packages, third party software like docker, ansible, git, curl etc).</li>
  <li>Dynamic dependencies (In-house tooling and configuration files that are constantly iterated on)</li>
</ul>

<p>We are going to use Packer to pack all of our static dependencies and Ansible to provision our dynamic dependencies inside of Vagrant.</p>

<p>A simple example to clarify what I mean:</p>

<p>At Traintracks we have a remote working culture but most of our engineers are in Beijing.</p>

<p>That means that everything that requires free and fast access to the greater internet goes into our static dependencies (Packer). Third party installation scripts might be pulling from Amazon S3 (blocked in China).</p>

<p>Kubernetes is downloaded from google servers, which means it is also blocked.</p>

<p>Due to internet connectivity and speed limitations we want these types of dependencies to be downloaded and configured once and then distributed to all the team members without anyone having to jump on a VPN to download software dependencies.</p>

<p>Of course we could host these dependencies on our own servers and we very often do but for dependencies that are not being changed a lot (our static dependencies) we prefer to grab them directly from the correct source once, and distribute everywhere just like we do for our production servers.</p>

<p>So, enough talking and let’s get to it!</p>

<p><strong>Prerequisites</strong></p>

<ul>
  <li>Packer 0.10 or above</li>
  <li>Vagrant 1.8.1 or above.</li>
  <li>Ansible 2.0 or above.</li>
</ul>

<p>Assuming you’re on a mac and use <a href="http://brew.sh">homebrew</a>:</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>brew cask install virtualbox
<span class="gp">$ </span>brew cask install vagrant
<span class="gp">$ </span>brew install packer
<span class="gp">$ </span>brew install ansible
</code></pre>
</div>

<p><strong>Packer (Static dependencies)</strong></p>

<p>We have prepared a boilerplate for a Packer configuration that is very similar to the one we use at Traintracks that we will use as our base.</p>

<p>This boilerplate will give you a box containing:</p>

<ul>
  <li>Ubuntu 16.04</li>
  <li>VirtualBox Guest Additions</li>
  <li>Docker, kubectl and kargo</li>
  <li>git, wget, curl, vim, zsh, htop, tmux, ntp</li>
</ul>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>git clone git@github.com:traintracks/devbox.git
<span class="gp">$ </span><span class="nb">cd </span>devbox
</code></pre>
</div>
<p>Lets start by inspecting the packer folder</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code>packer
├── ansible
│   └── playbook.yml
├── devbox.json
├── files
│   └── motd
├── http
│   └── preseed.cfg
└── scripts
    ├── ansible.sh
    ├── cleanup.sh
    ├── install.sh
    └── setup.sh
</code></pre>
</div>
<p><strong>devbox.json</strong> is the file that explains to packer how to build the devbox, which files to copy and which scripts to run.
You can also add provisioners for other image types (ec2, vmware etc) in here.
If you want to use another base operating system you define that
in here and provide an url and hash sum to the base image.</p>

<p><strong>preseed.cfg</strong> will be fetched by the Ubuntu installer from a local web server that Packer has spun-up that will automate the Ubuntu installation by automatically providing answers to all of the installation prompts.</p>

<p><strong>scripts folder</strong> contains scripts that makes little sense to perform with ansible. Eg: ansible.sh installs ansible and cleanup.sh does final cleanup before exporting the box.</p>

<p><strong>playbook.yml</strong> is the ansible playbook where you define packages to be installed and other configurations.</p>

<p>To customise the devbox to your needs you will mainly be interested in devbox.json and playbook.yml.</p>

<p>Now we can go ahead and build the devbox with packer.</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span><span class="nb">cd </span>packer
<span class="gp">$ </span>packer build devbox.json
</code></pre>
</div>
<p><em>To see the installation progress you can either go from the VirtualBox UI, watch the preview screen, select Show from Machine menu, or set headless to false in the devbox.json file.</em></p>

<p><strong>Dynamic dependencies</strong></p>

<p>As mentioned earlier your team might have tooling or configuration that is frequently updated which you want to propagate throughout your team more often than you want to build a new box with Packer.</p>

<p>One example could be a company wide ssh config or a common zshrc file.
The boilerplate contains a simple example on how this is done.</p>

<p>Lets have a look inside of the Vagrantfile.</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span><span class="nb">cd</span> ..
<span class="gp">$ </span>cat Vagrantfile
</code></pre>
</div>

<p>Check out the lines between  <code class="highlighter-rouge"># PROVISION START</code> and <code class="highlighter-rouge"># PROVISION END</code></p>

<p>The first three lines copies your host machines default ssh keys into the devbox so that you can access your remote machines from the devbox as you would from your host machine.
We also copy your git config so that you can make git commits from within the devbox.</p>

<p>After that you can see that we are calling ansible to do the rest of the provisioning using the ansible/playbook.yml file.</p>

<div class="language-yaml highlighter-rouge"><pre class="highlight"><code>  <span class="s">---</span>
  <span class="s">- hosts</span><span class="pi">:</span> <span class="s">all</span>
    <span class="s">tasks</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">name</span><span class="pi">:</span> <span class="s">Copy zshrc</span>
      <span class="s">copy</span><span class="pi">:</span> <span class="s">src=files/zshrc dest=/home/vagrant/.zshrc</span>
    <span class="pi">-</span> <span class="s">name</span><span class="pi">:</span> <span class="s">Set shell to zsh</span>
      <span class="s">become</span><span class="pi">:</span> <span class="s">yes</span>
      <span class="s">user</span><span class="pi">:</span> <span class="s">name=vagrant shell=/bin/zsh</span>
</code></pre>
</div>
<p>Currently all it does is setting the default shell to zsh and copies a zshrc file into the vagrant home folder but it serves as a template for you to add all of the other tools and configurations that go into the devbox.</p>

<p>For example you can add a company wide ssh config that is pushed to git and all your team mates have to do to get the new config is a <code class="highlighter-rouge">git pull</code> followed by a <code class="highlighter-rouge">vagrant provision</code>.</p>

<p>Once you notice a dynamic dependency is being updated less frequently you can move it to the static dependencies instead (A mere copy paste between two ansible files).</p>

<p>Now lets add the box to vagrant, provision it and start it up!</p>
<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span><span class="nb">cd</span> ..
<span class="gp">$ </span>vagrant box add devbox packer/builds/devbox.box
<span class="gp">$ </span>vagrant up
</code></pre>
</div>

<p>If everything went well you should be greeted with a shell looking like this.</p>

<p><img src="/assets/devbox.png" alt="" /></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/devops/2016/07/05/safeguarding_your_deployments_with_packer/">
        Safeguarding your deployments with Packer
      </a>
    </h1>

    <span class="post-date">05 Jul 2016</span>

    <p>For me, one of the greatest challenges of building our solution was making sure we had the ability to deploy on-premise, or on any cloud provider.</p>

<p>At the root of all the tools we use to make this possible is <a href="https://www.packer.io/">Packer</a>.</p>

<blockquote>
  <p>“Packer is an open source tool for creating identical machine images for multiple platforms from a single source configuration.” - Hashicorp</p>
</blockquote>

<p>By using Packer we know can pack all of our applications and their dependencies into a deployable image, through a single configuration, that can be easily installed on our cloud clusters or on-premise bare metal clusters,</p>

<p>Traditionally when deploying a cluster of machines you often do the provisioning through a configuration management tool like Ansible, Puppet or Chef.</p>

<p>But whether you are provisioning thousands of servers or only a dozen, not only will it take a considerable amount of time but also every step along the way things can fail and very often does, even with idempotent provisioning scripts.</p>

<p>That’s because even if it ran correctly last time, maybe links on the internet have changed or an external software package was updated during provisioning and it no longer works. You end up trusting a lot of the internet to be stable which just does not happen in reality.</p>

<p><a href="http://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/">How one developer just broke Node, Babel and thousands of projects in 11 lines of JavaScript</a></p>

<p>By using Packer to pack your OS and dependencies into one image you have defended against the instability of the outside world without sacrificing reproducibility. Throw packer into your CI/CD pipeline and you can achieve an immutable server configuration and not have to worry about any of your cluster nodes ending up in an inconsistent state. When one gets ill you don’t nurse it, you throw it away and get a new one aligning to the <a href="https://blog.engineyard.com/2014/pets-vs-cattle">Pets vs Cattle</a> analogy.
<img src="/assets/sysadmin.jpg" alt="Happy sysadmin" />
<em>Happy sysadmin</em></p>

<p>We have seen in theory how packer can be applied to your production servers, but can the same concept be applied to your development environment?</p>

<p>The short answer is yes, so stay tuned (feel free to sign up for our mailing list), because in the next article we will get you familiar with Packer while setting up a “devbox” for you and your team. It’s been a great time saver for me, and I hope it will help you too.</p>

<p><a href="/devops/2016/07/05/safeguarding_your_deployments_with_packer">Check out a follow-up post on how to build a devbox with Packer, Vagrant and Ansible.</a></p>

  </div>
  
</div>

<div class="pagination">
  
    <span class="pagination-item older">Older</span>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>
    </div>

  </body>
</html>
